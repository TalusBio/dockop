{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some indices\n",
    "Even the sparse matrices won't fit in memory. So we will have to loop through them when making predictions or sampling random items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of items:\n",
    "indptr = [0]\n",
    "\n",
    "for chunkID in range(10):\n",
    "    scores = np.load(f'../processed_data/AmpC_all{chunkID}.npy')\n",
    "    indptr.append(indptr[-1] + scores.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.concatenate([np.load(f'../processed_data/AmpC_all{i}.npy') for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions to handle the slabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFPs(chunkID, indptr, isTrain):\n",
    "    fp = sparse.load_npz(f'../processed_data/AmpC_all{chunkID}.npz')\n",
    "    mask = isTrain[indptr[chunkID]:indptr[chunkID+1]]\n",
    "    return fp[mask]\n",
    "\n",
    "def buildTrain(indptr, isTrain, verbose=0):\n",
    "    if verbose:\n",
    "        print('building training matrix')\n",
    "    fps = sparse.vstack([extractFPs(i, indptr, isTrain) for i in range(10)])\n",
    "    return fps\n",
    "\n",
    "def chunkPredictProba(model, indptr, isTrain, verbose=0):\n",
    "    if verbose:\n",
    "        print('predicting probabilities')\n",
    "    probas = []\n",
    "    for chunkID in range(10):\n",
    "        fps = extractFPs(chunkID, indptr, ~isTrain)\n",
    "        proba = model.predict_proba(fps)[:,1]\n",
    "        probas.append(proba)\n",
    "    return np.concatenate(probas)\n",
    "\n",
    "def chunkPredict(model, indptr, isTrain, verbose=0):\n",
    "    if verbose:\n",
    "        print('predicting probabilities')\n",
    "    preds = []\n",
    "    for chunkID in range(10):\n",
    "        fps = extractFPs(chunkID, indptr, ~isTrain)\n",
    "        pred = -1*model.predict(fps) #best scoring will now be on top (like the proba)\n",
    "        preds.append(pred)\n",
    "    return np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and RF regressor and Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import Ridge\n",
    "model = LogisticRegression(max_iter=10000, C=0.1)\n",
    "#model = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How long to find the 50k - 500k top 0.4%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSetSizes = [5000, 10_000] + [10000*2<<i for i in range(0,8)]\n",
    "desiredNumLigands = [25_000, 50_000, 100_000, 200_000, 300_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.33796296, 144.67592593, 289.35185185, 578.7037037 ,\n",
       "       868.05555556])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(desiredNumLigands) / 0.004 / 60 / 60 / 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building training matrix\n",
      "predicting probabilities\n",
      "1 5000 25000 114732\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "2 10000 25000 106772\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "3 20000 25000 115994\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "4 40000 25000 132108\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "5 80000 25000 163991\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "6 160000 25000 238455\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "7 320000 25000 392069\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "8 640000 25000 703429\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "9 1280000 25000 1334626\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "10 2560000 25000 2599583\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "11 5000 50000 283599\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "12 10000 50000 271329\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "13 20000 50000 240087\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "14 40000 50000 236545\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "15 80000 50000 261348\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "16 160000 50000 326539\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "17 320000 50000 474531\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "18 640000 50000 778368\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "19 1280000 50000 1405815\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "20 2560000 50000 2665460\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "21 5000 100000 532945\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "22 10000 100000 517573\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "23 20000 100000 515562\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "24 40000 100000 488236\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "25 80000 100000 516348\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "26 160000 100000 569774\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "27 320000 100000 689957\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "28 640000 100000 972653\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "29 1280000 100000 1579413\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "30 2560000 100000 2826091\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "31 5000 200000 1283982\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "32 10000 200000 1218021\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "33 20000 200000 1170580\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "34 40000 200000 1128087\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "35 80000 200000 1118467\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "36 160000 200000 1148942\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "37 320000 200000 1220731\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "38 640000 200000 1476673\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "39 1280000 200000 2061325\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "40 2560000 200000 3275618\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "41 5000 300000 4475952\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "42 10000 300000 2782567\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "43 20000 300000 2436419\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "44 40000 300000 2283910\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "45 80000 300000 2177679\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "46 160000 300000 2114305\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "47 320000 300000 2129490\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "48 640000 300000 2306997\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "49 1280000 300000 2835903\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "50 2560000 300000 4035710\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "51 5000 25000 113156\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "52 10000 25000 123437\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "53 20000 25000 127251\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "54 40000 25000 142124\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "55 80000 25000 171028\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "56 160000 25000 242482\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "57 320000 25000 393337\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "58 640000 25000 704492\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "59 1280000 25000 1332681\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "60 2560000 25000 2599157\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "61 5000 50000 268591\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "62 10000 50000 226682\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "63 20000 50000 245188\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "64 40000 50000 241462\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "65 80000 50000 266087\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "66 160000 50000 327643\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "67 320000 50000 477537\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "68 640000 50000 784446\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "69 1280000 50000 1406555\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "70 2560000 50000 2664264\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "71 5000 100000 590435\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "72 10000 100000 552122\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "73 20000 100000 527483\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "74 40000 100000 493204\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "75 80000 100000 491782\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "76 160000 100000 544309\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "77 320000 100000 678426\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "78 640000 100000 963446\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "79 1280000 100000 1576393\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "80 2560000 100000 2825512\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "81 5000 200000 1293468\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "82 10000 200000 1354556\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "83 20000 200000 1233679\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "84 40000 200000 1218292\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "85 80000 200000 1155554\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "86 160000 200000 1138697\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "87 320000 200000 1234806\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "88 640000 200000 1494524\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "89 1280000 200000 2060279\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "90 2560000 200000 3278107\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "91 5000 300000 3944403\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "92 10000 300000 2524507\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "93 20000 300000 2431261\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "94 40000 300000 2300341\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "95 80000 300000 2142736\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "96 160000 300000 2095156\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "97 320000 300000 2127419\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "98 640000 300000 2328066\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "99 1280000 300000 2863525\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "100 2560000 300000 4050581\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "101 5000 25000 111582\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "102 10000 25000 114066\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "103 20000 25000 118132\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "104 40000 25000 131184\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "105 80000 25000 166308\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "106 160000 25000 239011\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "107 320000 25000 389563\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "108 640000 25000 702899\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "109 1280000 25000 1335092\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "110 2560000 25000 2600912\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "111 5000 50000 257661\n",
      "building training matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting probabilities\n",
      "112 10000 50000 243509\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "113 20000 50000 234265\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "114 40000 50000 237884\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "115 80000 50000 266192\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "116 160000 50000 331464\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "117 320000 50000 480341\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "118 640000 50000 785669\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "119 1280000 50000 1409031\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "120 2560000 50000 2667132\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "121 5000 100000 582095\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "122 10000 100000 531280\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "123 20000 100000 487450\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "124 40000 100000 464802\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "125 80000 100000 491637\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "126 160000 100000 546904\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "127 320000 100000 682438\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "128 640000 100000 970893\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "129 1280000 100000 1580045\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "130 2560000 100000 2827781\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "131 5000 200000 1220453\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "132 10000 200000 1181374\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "133 20000 200000 1193503\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "134 40000 200000 1187622\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "135 80000 200000 1149140\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "136 160000 200000 1131054\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "137 320000 200000 1216515\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "138 640000 200000 1477936\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "139 1280000 200000 2055870\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "140 2560000 200000 3278282\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "141 5000 300000 4371183\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "142 10000 300000 2975507\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "143 20000 300000 2590974\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "144 40000 300000 2363851\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "145 80000 300000 2141283\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "146 160000 300000 2109220\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "147 320000 300000 2140483\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "148 640000 300000 2333355\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "149 1280000 300000 2869110\n",
      "building training matrix\n",
      "predicting probabilities\n",
      "150 2560000 300000 4053175\n"
     ]
    }
   ],
   "source": [
    "test_cutoff = np.percentile(scores, 0.4)\n",
    "\n",
    "topK = scores<test_cutoff\n",
    "\n",
    "#df = pd.DataFrame(columns=['Algorithm', 'Training size', 'N ligands explored', '% top-k found'])\n",
    "df = pd.DataFrame(columns=['Algorithm', 'Training size', 'N hits wanted', 'N hits explored'])\n",
    "count=0\n",
    "\n",
    "for i in range(3):\n",
    "    for numWanted in desiredNumLigands:\n",
    "        idx = np.arange(scores.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        for size in trainingSetSizes:\n",
    "            #split indices into train and test:\n",
    "            train = idx[:size].copy()\n",
    "            test = idx[size:].copy()\n",
    "            train.sort()\n",
    "            test.sort()\n",
    "    \n",
    "            #generate a 'is a training instance' mask. \n",
    "            isTrain = np.zeros(scores.shape[0]).astype(bool)\n",
    "            isTrain[train]=True\n",
    "    \n",
    "            #topK molecules already found in the training set:\n",
    "            numFound = topK[train].sum()\n",
    "            numRequired = numWanted - numFound\n",
    "            \n",
    "            #fit model:\n",
    "            cutoff = np.percentile(scores[isTrain],0.8)\n",
    "            model.fit(buildTrain(indptr, isTrain, 1), scores[isTrain]<cutoff)\n",
    "\n",
    "            #predict (slowest step):\n",
    "            proba = chunkPredictProba(model, indptr, isTrain, 1)\n",
    "        \n",
    "            #rank the probabilities\n",
    "            proba_sorted = (-proba).argsort()\n",
    "            \n",
    "            #sorted the unseen instances by probability (highest prob first):\n",
    "            test = test[proba_sorted]\n",
    "\n",
    "            #topK molecules already found in the training set:\n",
    "            numSampled = np.argmax(np.cumsum(topK[test])>numRequired)\n",
    "            \n",
    "            df.loc[count] = ['morgan_feat', size, numWanted, numSampled+size]\n",
    "            count+=1\n",
    "            print(count, size, numWanted, numSampled+size)\n",
    "                \n",
    "            #df.to_csv('../processed_data/AmpC_single_'+str(0.4)+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
