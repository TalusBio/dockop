{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from functools import lru_cache\n",
    "from sklearn.metrics import recall_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('default')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.renderers.enable('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CHUNKS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some indices\n",
    "Even the sparse matrices won't fit in memory. So we will have to loop through them when making predictions or sampling random items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_EMBEDDINGS = True\n",
    "MODEL = \"_r1\"\n",
    "CLASSIFIER = \"_rf_reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECEPTOR = \"AmpC\"\n",
    "DATA_DIR = \"/mnt/efs/AmpC_data\"\n",
    "\n",
    "MODEL_PATH = \"/mnt/efs/mol2vec/examples/models/model_300dim.pkl\"\n",
    "UNCOMMON = \"UNK\"\n",
    "\n",
    "if USE_EMBEDDINGS:\n",
    "    OUTPUT_RESULTS_FILE = f\"{RECEPTOR}_embedding_results{MODEL}{CLASSIFIER}.csv\"\n",
    "else:\n",
    "    OUTPUT_RESULTS_FILE = f\"{RECEPTOR}_results{CLASSIFIER}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of items:\n",
    "indptr = [0]\n",
    "scores_lst = []\n",
    "\n",
    "for chunk_id in range(NUM_CHUNKS):\n",
    "    scores = np.load(f\"{DATA_DIR}/{RECEPTOR}_scores_{chunk_id}{MODEL}.npy\")\n",
    "    indptr.append(indptr[-1] + scores.shape[0])\n",
    "    scores_lst.append(scores)\n",
    "    \n",
    "scores = np.concatenate(scores_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96214206,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(chunk_id, use_embeddings=True):\n",
    "    print(f\"Loading vectors {chunk_id}{MODEL}\", end=\"; \", flush=True)\n",
    "    if use_embeddings:\n",
    "        vectors = np.load(f\"{DATA_DIR}/{RECEPTOR}_embeddings_{chunk_id}{MODEL}.npy\")\n",
    "    else:\n",
    "        vectors = sparse.load_npz(f\"{DATA_DIR}/{RECEPTOR}_fingerprints_{chunk_id}.npz\")\n",
    "    return vectors\n",
    "\n",
    "def extract_vectors(chunk_id, indptr, is_train):\n",
    "    print(f\"Extracting vectors: {chunk_id}\", end=\"; \", flush=True)\n",
    "    vectors = load_vectors(chunk_id, use_embeddings=USE_EMBEDDINGS)\n",
    "    mask = is_train[indptr[chunk_id]:indptr[chunk_id+1]]\n",
    "    return vectors[mask].astype(int)\n",
    "\n",
    "def build_train(indptr, is_train):\n",
    "    print(\"Building training set\", end=\"; \", flush=True)\n",
    "    if USE_EMBEDDINGS:\n",
    "        vectors = np.vstack([extract_vectors(i, tuple(indptr), is_train) for i in range(NUM_CHUNKS)])\n",
    "    else:\n",
    "        vectors = sparse.vstack([extract_vectors(i, tuple(indptr), is_train) for i in range(NUM_CHUNKS)])  \n",
    "    return vectors\n",
    "\n",
    "def chunk_predict_proba(model, indptr, is_train):\n",
    "    print(\"Predicting proba\", end=\"; \", flush=True)\n",
    "    probas = []\n",
    "    for chunk_id in range(NUM_CHUNKS):\n",
    "        vectors = extract_vectors(chunk_id, indptr, ~is_train)\n",
    "        proba = model.predict_proba(vectors)[:,1]\n",
    "        probas.append(proba)\n",
    "    return np.concatenate(probas)\n",
    "\n",
    "def chunk_predict(model, indptr, is_train):\n",
    "    print(\"Predicting scores\", end=\"; \", flush=True)\n",
    "    preds = []\n",
    "    for chunk_id in range(NUM_CHUNKS):\n",
    "        vectors = extract_vectors(chunk_id, indptr, ~is_train)\n",
    "        pred = model.predict(vectors)\n",
    "        preds.append(pred)\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "def chunk_get_mean_and_var(model, indptr, is_train):\n",
    "    print(\"Getting mean and var\", end=\"; \", flush=True)\n",
    "    preds = []\n",
    "    for chunk_id in range(NUM_CHUNKS):\n",
    "        vectors = extract_vectors(chunk_id, indptr, ~is_train)\n",
    "        pred = np.zeros((len(vectors), len(model.estimators_)))\n",
    "        for j, submodel in enumerate(model.estimators_):\n",
    "            pred[:, j] = submodel.predict(vectors)\n",
    "        preds.append(pred)\n",
    "    preds = np.concatenate(preds)\n",
    "    return np.mean(preds, axis=1), np.var(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(Y_mean: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Greedy acquisition score\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_mean : np.ndarray\n",
    "        the mean predicted y values\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the greedy acquisition scores\n",
    "    \"\"\"\n",
    "    return Y_mean\n",
    "\n",
    "def ucb(Y_mean: np.ndarray, Y_var: np.ndarray, beta: int = 2) -> float:\n",
    "    \"\"\"Upper confidence bound acquisition score\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_mean : np.ndarray\n",
    "    Y_var : np.ndarray\n",
    "        the variance of the mean predicted y values\n",
    "    beta : int (Default = 2)\n",
    "        the number of standard deviations to add to Y_mean\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        the upper confidence bound acquisition scores\n",
    "    \"\"\"\n",
    "    return Y_mean + beta*np.sqrt(Y_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = LogisticRegression(max_iter=10000, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor(\n",
    "# #     objective=\"reg:squaredlogerror\"\n",
    "#     use_label_encoder=False\n",
    "# )\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(\n",
    "#     objective=\"binary:logistic\",\n",
    "#     use_label_encoder=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K_THRESHOLD = 50_000\n",
    "N_QUERIES = 5\n",
    "N_FOLDS = 3\n",
    "EPSILON = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: -1, Recall: 0.00418\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 1, Recall: 0.27778\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 2, Recall: 0.53428\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 3, Recall: 0.66412\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 4, Recall: 0.78316\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 5, Recall: 0.8563\n",
      "Iteration: -1, Recall: 0.00414\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 1, Recall: 0.29194\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 2, Recall: 0.51086\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 3, Recall: 0.6826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 4, Recall: 0.7778\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 5, Recall: 0.87438\n",
      "Iteration: -1, Recall: 0.0041\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; \n",
      "Iteration: 1, Recall: 0.28002\n",
      "Building training set; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; Extracting vectors: 5; Loading vectors 5_r1; Extracting vectors: 6; Loading vectors 6_r1; Extracting vectors: 7; Loading vectors 7_r1; Extracting vectors: 8; Loading vectors 8_r1; Extracting vectors: 9; Loading vectors 9_r1; Fitting model; Predicting scores; Extracting vectors: 0; Loading vectors 0_r1; Extracting vectors: 1; Loading vectors 1_r1; Extracting vectors: 2; Loading vectors 2_r1; Extracting vectors: 3; Loading vectors 3_r1; Extracting vectors: 4; Loading vectors 4_r1; "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-6c7b5b50caf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# predict (slowest step) for logreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;31m#             preds = chunk_predict_proba(model, indptr, is_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-e88ae51e281b>\u001b[0m in \u001b[0;36mchunk_predict\u001b[0;34m(model, indptr, is_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CHUNKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dockop/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m    821\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dockop/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mcsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m             _check_call(\n\u001b[0;32m-> 1864\u001b[0;31m                 _LIB.XGBoosterPredictFromCSR(\n\u001b[0m\u001b[1;32m   1865\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                     \u001b[0m_array_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training_set_fractions = [0.004, 0.002, 0.001]\n",
    "training_set_sizes = [400_000]\n",
    "\n",
    "# percentile = 0.3\n",
    "\n",
    "cols = ['Algorithm', 'Training size', 'N ligands explored', '% top-k found']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "n_labeled_examples = scores.shape[0]\n",
    "\n",
    "y_test = (scores.argsort().argsort() < TOP_K_THRESHOLD)\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    for size in training_set_sizes:\n",
    "#     for fraction in training_set_fractions:\n",
    "#         size = int(len(scores) * fraction)\n",
    "        \n",
    "        # split indices into train and pool\n",
    "        all_indices = np.arange(n_labeled_examples)\n",
    "        train_indices = np.array(random.sample(range(n_labeled_examples+1), k=size))\n",
    "        pool_indices = np.delete(all_indices, train_indices, axis=0)\n",
    "        train_indices.sort()\n",
    "        pool_indices.sort()\n",
    "\n",
    "        # generate a 'is a training instance' mask. \n",
    "        is_train = np.zeros(n_labeled_examples).astype(bool)\n",
    "        is_train[train_indices] = True\n",
    "\n",
    "        # Calculate recall\n",
    "        y_pred = np.zeros(n_labeled_examples).astype(int)\n",
    "        y_pred[train_indices] = 1\n",
    "        recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "        \n",
    "        df = df.append(pd.DataFrame([[\"morgan_feat\", size, train_indices.shape[0], recall]],\n",
    "                                    columns=cols),\n",
    "                      ignore_index=True)\n",
    "        print(f\"Iteration: -1, Recall: {recall}\")\n",
    "\n",
    "        # estimate the cutoff once, from the initial random sample:\n",
    "#         cutoff = np.percentile(scores[train_indices], percentile)\n",
    "\n",
    "        for i in range(N_QUERIES):\n",
    "            # fit logreg model\n",
    "            x_train = build_train(indptr, is_train)\n",
    "            y_train = scores[is_train]\n",
    "#             y_train = scores[is_train] < cutoff\n",
    "\n",
    "            print(\"Fitting model\", end=\"; \", flush=True)\n",
    "            model.fit(\n",
    "                x_train,\n",
    "                y_train, \n",
    "#                 eval_metric=\"rmsle\"\n",
    "#                 eval_metric=\"rmse\"\n",
    "            )\n",
    "\n",
    "            # predict (slowest step) for logreg\n",
    "#             preds = chunk_predict(model, indptr, is_train)\n",
    "#             preds = chunk_predict_proba(model, indptr, is_train)\n",
    "            y_mean, y_var = chunk_get_mean_and_var(model, indptr, is_train)\n",
    "            utility = ucb(Y_mean=y_mean, Y_var=y_var)\n",
    "            \n",
    "            # get some exploration indices\n",
    "            exploration_indices = np.random.choice(\n",
    "                np.arange(utility.size), replace=False,\n",
    "                size=int(size * EPSILON)\n",
    "            )\n",
    "            utility[exploration_indices] = np.inf\n",
    "\n",
    "            # rank the probabilities (negative is better, otherwise we'd have to do (-preds).argsort())\n",
    "#             preds_sorted = preds.argsort()\n",
    "#             preds_sorted = (-preds).argsort()\n",
    "            preds_sorted = utility.argsort()\n",
    "\n",
    "            # rank the unseen instances\n",
    "            pool_indices = pool_indices[preds_sorted]\n",
    "\n",
    "            # now append the next N instances from the rank ordered unseen instances onto the training set\n",
    "            train_indices = np.concatenate([train_indices, pool_indices[:size]])\n",
    "\n",
    "            # update the isTrain mask and remove those training instances from the test set\n",
    "            is_train[train_indices] = True\n",
    "            pool_indices = pool_indices[size:]\n",
    "\n",
    "            # keep the train and test idx arrays sorted so they agree with the chunked* methods\n",
    "            pool_indices.sort()\n",
    "            train_indices.sort()\n",
    "\n",
    "            # Calculate recall\n",
    "            y_pred = np.zeros(n_labeled_examples).astype(int)\n",
    "            y_pred[train_indices] = 1\n",
    "            recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
    "                        \n",
    "            df = df.append(pd.DataFrame([[\"morgan_feat\", size, train_indices.shape[0], recall]],\n",
    "                                        columns=cols),\n",
    "                          ignore_index=True)\n",
    "            \n",
    "            print(f\"\\nIteration: {i+1}, Recall: {recall}\")\n",
    "                        \n",
    "            df.to_csv(f\"{DATA_DIR}/{OUTPUT_RESULTS_FILE}\")\n",
    "\n",
    "df.to_csv(f\"{DATA_DIR}/{OUTPUT_RESULTS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results look like this:\n",
    "And they can be plotted using `./plot_scripts/plot_wholedataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../processed_data/ampc_reconstruction_0.3_1_.csv', index_col=0)\n",
    "df0['Algorithm'] = 'AmpC:LogReg (lewis)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f\"{DATA_DIR}/{RECEPTOR}_embedding_results_r1.csv\", index_col=0)\n",
    "df1['Algorithm'] = 'AmpC:LogReg (embeddings)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(f\"{DATA_DIR}/{RECEPTOR}_embedding_results_r1_xgb.csv\", index_col=0)\n",
    "df2['Algorithm'] = 'AmpC:LogReg (embeddings, xgb)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(f\"{DATA_DIR}/{RECEPTOR}_results_xgb.csv\", index_col=0)\n",
    "df3['Algorithm'] = 'AmpC:LogReg (fps, xgb)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df33 = pd.read_csv(f\"{DATA_DIR}/{RECEPTOR}_results_xgb_reg.csv\", index_col=0)\n",
    "df33['Algorithm'] = 'AmpC:LogReg (fps, xgb_reg)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(f\"{DATA_DIR}/{RECEPTOR}_results.csv\", index_col=0)\n",
    "df4['Algorithm'] = 'AmpC:LogReg (fps)'\n",
    "df4.loc[df4[\"Training size\"] == 384_856, \"Training size\"] = 400_000 \n",
    "df4.loc[df4[\"Training size\"] == 192_428, \"Training size\"] = 200_000\n",
    "df4.loc[df4[\"Training size\"] == 96_214, \"Training size\"] = 100_000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df0, df1, df2, df3, df33, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_results = [['AmpC:RF (Graff)', 400_000, 71.4, 2.1], \n",
    "                ['AmpC:NN (Graff)', 400_000, 74.7, 1.4],\n",
    "                ['AmpC:MPN (Graff)',400_000, 87.9, 2.3],\n",
    "                ['AmpC:RF (Graff)', 200_000, 45.5, 1.8],\n",
    "                ['AmpC:NN (Graff)', 200_000, 52.8, 0.5],\n",
    "                ['AmpC:MPN (Graff)', 200_000, 67.1, 2.1],\n",
    "                ['AmpC:RF (Graff)', 100_000, 24.0, 2.2],\n",
    "                ['AmpC:NN (Graff)', 100_000 , 33.3,0.3],\n",
    "                ['AmpC:MPN (Graff)', 100_000, 52.0, 0.5]]\n",
    "\n",
    "coley = pd.DataFrame(columns=['Algorithm', 'Training size', 'N ligands explored', '% top-k found'])\n",
    "count = 0 \n",
    "for res in prev_results:\n",
    "    desired_std_dev = res[3]\n",
    "    samples = np.array([-1,0,1]).astype(float)\n",
    "    samples *= (desired_std_dev/np.std(samples))\n",
    "    for s in samples:\n",
    "        coley.loc[count] = [res[0], res[1], res[1]*6, (s+res[2])/100]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([df, coley])\n",
    "concat['% top-k found'] *= 100\n",
    "concat.columns = ['Algorithm', 'Training set size', 'N ligands explored', '% top-k found']\n",
    "concat['Training set size'] = concat['Training set size'].apply(lambda num: f\"{num:,d}\",)\n",
    "concat['Computation days (single CPU)'] = concat['N ligands explored'] / 60 / 60 /24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bars = alt.Chart(concat).mark_errorbar(extent='ci').encode(\n",
    "  x=alt.X('N ligands explored:Q',title='Number of ligands sampled'),\n",
    "  y=alt.Y('% top-k found:Q', title='% top 50,000 found'),\n",
    "    color=alt.Color('Algorithm')\n",
    ")\n",
    "\n",
    "points = alt.Chart(concat).mark_point(filled=False, size=40, color='black').encode(\n",
    "  x=alt.X('N ligands explored:Q'),\n",
    "  y=alt.Y('% top-k found:Q',aggregate='mean',title='% top 50,000 found'),\n",
    "    color=alt.Color('Algorithm'),\n",
    "    tooltip=alt.Tooltip('% top-k found:Q',aggregate='mean',title='% top 50,000 found')\n",
    ")\n",
    "\n",
    "line = alt.Chart(concat).mark_line(color='black',size=2,opacity=0.5).encode(\n",
    "  x=alt.X('N ligands explored:Q'),\n",
    "  y=alt.Y('% top-k found:Q',aggregate='mean',title='% top 50,000 found'),\n",
    "    color=alt.Color('Algorithm')\n",
    ")\n",
    "\n",
    "ch = (error_bars+points+line).properties(height=300,width=150).facet(\n",
    "    column=alt.Column('Training set size:N',sort=alt.Sort([0.004, 0.002, 0.001])),\n",
    ").resolve_scale(x='independent')\n",
    "# ch.save('../../figures/active_learning_percentage.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-59a5ab44fd834d39b11ca238c364199c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-59a5ab44fd834d39b11ca238c364199c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-59a5ab44fd834d39b11ca238c364199c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d9311491cfe3a85ba03c25ecabe4eb54\"}, \"facet\": {\"column\": {\"type\": \"nominal\", \"field\": \"Training set size\", \"sort\": [0.004, 0.002, 0.001]}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"errorbar\", \"extent\": \"ci\"}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Algorithm\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"N ligands explored\", \"title\": \"Number of ligands sampled\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"% top-k found\", \"title\": \"% top 50,000 found\"}}}, {\"mark\": {\"type\": \"point\", \"color\": \"black\", \"filled\": false, \"size\": 40}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Algorithm\"}, \"tooltip\": {\"type\": \"quantitative\", \"aggregate\": \"mean\", \"field\": \"% top-k found\", \"title\": \"% top 50,000 found\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"N ligands explored\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"mean\", \"field\": \"% top-k found\", \"title\": \"% top 50,000 found\"}}}, {\"mark\": {\"type\": \"line\", \"color\": \"black\", \"opacity\": 0.5, \"size\": 2}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Algorithm\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"N ligands explored\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"mean\", \"field\": \"% top-k found\", \"title\": \"% top 50,000 found\"}}}], \"height\": 300, \"width\": 150}, \"resolve\": {\"scale\": {\"x\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-d9311491cfe3a85ba03c25ecabe4eb54\": [{\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.406, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 41.796, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 69.072, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 81.326, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 87.818, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 91.494, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 200000, \"% top-k found\": 0.2, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 400000, \"% top-k found\": 22.608, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 600000, \"% top-k found\": 47.548, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 800000, \"% top-k found\": 60.672000000000004, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1000000, \"% top-k found\": 68.996, \"Computation days (single CPU)\": 11.574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 74.872, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 100000, \"% top-k found\": 0.098, \"Computation days (single CPU)\": 1.1574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 200000, \"% top-k found\": 11.544, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 300000, \"% top-k found\": 27.122, \"Computation days (single CPU)\": 3.472222222222222}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 400000, \"% top-k found\": 41.099999999999994, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 500000, \"% top-k found\": 50.292, \"Computation days (single CPU)\": 5.787037037037037}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 57.05, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.466, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 41.448, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 68.768, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 81.378, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 88.02, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 91.574, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 200000, \"% top-k found\": 0.246, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 400000, \"% top-k found\": 22.98, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 600000, \"% top-k found\": 47.332, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 800000, \"% top-k found\": 61.464, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1000000, \"% top-k found\": 70.18799999999999, \"Computation days (single CPU)\": 11.574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 76.632, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 100000, \"% top-k found\": 0.13999999999999999, \"Computation days (single CPU)\": 1.1574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 200000, \"% top-k found\": 11.382, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 300000, \"% top-k found\": 28.164, \"Computation days (single CPU)\": 3.472222222222222}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 400000, \"% top-k found\": 41.388000000000005, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 500000, \"% top-k found\": 50.205999999999996, \"Computation days (single CPU)\": 5.787037037037037}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 56.448, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.41000000000000003, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 39.648, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 68.978, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 81.364, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 87.888, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 91.678, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 200000, \"% top-k found\": 0.186, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 400000, \"% top-k found\": 22.182, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 600000, \"% top-k found\": 47.355999999999995, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 800000, \"% top-k found\": 61.224000000000004, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1000000, \"% top-k found\": 69.56, \"Computation days (single CPU)\": 11.574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 75.78, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 100000, \"% top-k found\": 0.092, \"Computation days (single CPU)\": 1.1574074074074074}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 200000, \"% top-k found\": 10.498000000000001, \"Computation days (single CPU)\": 2.314814814814815}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 300000, \"% top-k found\": 26.669999999999998, \"Computation days (single CPU)\": 3.472222222222222}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 400000, \"% top-k found\": 37.897999999999996, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 500000, \"% top-k found\": 46.760000000000005, \"Computation days (single CPU)\": 5.787037037037037}, {\"Algorithm\": \"AmpC:LogReg (lewis)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 53.776, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.418, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 28.977999999999998, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 42.424, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 55.779999999999994, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 64.39200000000001, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 70.44399999999999, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.392, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 28.322000000000003, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 43.194, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 56.442, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 64.95400000000001, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 70.502, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.4, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 30.081999999999997, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 44.13, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 56.862, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 64.60000000000001, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 70.262, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.428, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 25.044, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 49.884, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 64.104, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 73.45, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 79.386, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.434, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 24.008, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 49.874, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 64.30399999999999, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 73.894, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 80.414, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.378, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 24.706, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 49.448, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 64.14800000000001, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 73.8, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (embeddings, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 80.02, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.406, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 42.809999999999995, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 69.108, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 80.884, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 87.664, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 91.57600000000001, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.416, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 42.096000000000004, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.418, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 27.778000000000002, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 53.428, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 66.412, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 78.316, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 85.63, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.414, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 29.194, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1200000, \"% top-k found\": 51.086, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1600000, \"% top-k found\": 68.26, \"Computation days (single CPU)\": 18.51851851851852}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2000000, \"% top-k found\": 77.78, \"Computation days (single CPU)\": 23.14814814814815}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 87.438, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 400000, \"% top-k found\": 0.41000000000000003, \"Computation days (single CPU)\": 4.62962962962963}, {\"Algorithm\": \"AmpC:LogReg (fps, xgb_reg)\", \"Training set size\": \"400,000\", \"N ligands explored\": 800000, \"% top-k found\": 28.002, \"Computation days (single CPU)\": 9.25925925925926}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 384856, \"% top-k found\": 0.41000000000000003, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 769712, \"% top-k found\": 40.224, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1154568, \"% top-k found\": 67.974, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1539424, \"% top-k found\": 80.298, \"Computation days (single CPU)\": 17.817407407407405}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1924280, \"% top-k found\": 86.944, \"Computation days (single CPU)\": 22.27175925925926}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2309136, \"% top-k found\": 90.884, \"Computation days (single CPU)\": 26.72611111111111}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 192428, \"% top-k found\": 0.198, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 384856, \"% top-k found\": 22.43, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 577284, \"% top-k found\": 45.94, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 769712, \"% top-k found\": 60.068, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 962140, \"% top-k found\": 69.382, \"Computation days (single CPU)\": 11.13587962962963}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1154568, \"% top-k found\": 75.664, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 96214, \"% top-k found\": 0.098, \"Computation days (single CPU)\": 1.1135879629629628}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 192428, \"% top-k found\": 11.176, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 288642, \"% top-k found\": 26.732, \"Computation days (single CPU)\": 3.3407638888888886}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 384856, \"% top-k found\": 40.355999999999995, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 481070, \"% top-k found\": 49.728, \"Computation days (single CPU)\": 5.567939814814815}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 577284, \"% top-k found\": 56.426, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 384856, \"% top-k found\": 0.362, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 769712, \"% top-k found\": 38.07, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1154568, \"% top-k found\": 67.60199999999999, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1539424, \"% top-k found\": 80.25, \"Computation days (single CPU)\": 17.817407407407405}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1924280, \"% top-k found\": 86.954, \"Computation days (single CPU)\": 22.27175925925926}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2309136, \"% top-k found\": 90.802, \"Computation days (single CPU)\": 26.72611111111111}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 192428, \"% top-k found\": 0.192, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 384856, \"% top-k found\": 20.241999999999997, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 577284, \"% top-k found\": 44.274, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 769712, \"% top-k found\": 59.89, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 962140, \"% top-k found\": 69.664, \"Computation days (single CPU)\": 11.13587962962963}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1154568, \"% top-k found\": 76.24600000000001, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 96214, \"% top-k found\": 0.096, \"Computation days (single CPU)\": 1.1135879629629628}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 192428, \"% top-k found\": 9.766, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 288642, \"% top-k found\": 25.3, \"Computation days (single CPU)\": 3.3407638888888886}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 384856, \"% top-k found\": 37.246, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 481070, \"% top-k found\": 46.196, \"Computation days (single CPU)\": 5.567939814814815}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 577284, \"% top-k found\": 52.624, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 384856, \"% top-k found\": 0.41200000000000003, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 769712, \"% top-k found\": 40.526, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1154568, \"% top-k found\": 67.808, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1539424, \"% top-k found\": 80.276, \"Computation days (single CPU)\": 17.817407407407405}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 1924280, \"% top-k found\": 87.012, \"Computation days (single CPU)\": 22.27175925925926}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2309136, \"% top-k found\": 91.026, \"Computation days (single CPU)\": 26.72611111111111}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 192428, \"% top-k found\": 0.2, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 384856, \"% top-k found\": 21.854000000000003, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 577284, \"% top-k found\": 46.386, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 769712, \"% top-k found\": 59.864, \"Computation days (single CPU)\": 8.908703703703702}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 962140, \"% top-k found\": 67.71000000000001, \"Computation days (single CPU)\": 11.13587962962963}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1154568, \"% top-k found\": 74.17200000000001, \"Computation days (single CPU)\": 13.363055555555555}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 96214, \"% top-k found\": 0.094, \"Computation days (single CPU)\": 1.1135879629629628}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 192428, \"% top-k found\": 10.894, \"Computation days (single CPU)\": 2.2271759259259256}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 288642, \"% top-k found\": 27.132, \"Computation days (single CPU)\": 3.3407638888888886}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 384856, \"% top-k found\": 39.592, \"Computation days (single CPU)\": 4.454351851851851}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 481070, \"% top-k found\": 48.522, \"Computation days (single CPU)\": 5.567939814814815}, {\"Algorithm\": \"AmpC:LogReg (fps)\", \"Training set size\": \"100,000\", \"N ligands explored\": 577284, \"% top-k found\": 55.489999999999995, \"Computation days (single CPU)\": 6.681527777777777}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 68.82803577007766, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 71.4, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 73.97196422992235, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 72.98535718005178, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 74.7, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 76.41464281994823, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 85.08308679579935, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 87.9, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"400,000\", \"N ligands explored\": 2400000, \"% top-k found\": 90.71691320420067, \"Computation days (single CPU)\": 27.777777777777775}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 43.29545923149514, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 45.5, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 47.70454076850486, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 52.187627564304194, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 52.800000000000004, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 53.4123724356958, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 64.52803577007765, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 67.1, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"200,000\", \"N ligands explored\": 1200000, \"% top-k found\": 69.67196422992234, \"Computation days (single CPU)\": 13.888888888888888}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 21.305561282938505, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 24.0, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:RF (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 26.694438717061498, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 32.93257653858252, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 33.3, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:NN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 33.66742346141747, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 51.3876275643042, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 52.0, \"Computation days (single CPU)\": 6.944444444444444}, {\"Algorithm\": \"AmpC:MPN (Graff)\", \"Training set size\": \"100,000\", \"N ligands explored\": 600000, \"% top-k found\": 52.6123724356958, \"Computation days (single CPU)\": 6.944444444444444}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dockop",
   "language": "python",
   "name": "dockop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
